老师，我有一些问题想问一下。
目前的数据集大多是由部署推荐系统产生收集的，这部分数据本身就是有偏的，在使用这种数据集进行去偏的时候会有一点弊端。还有一种就是利用完全随测试获取的数据集，比如说让用户填写调查问卷，由于给每个用户的问卷中的项目不受展示策略以及用户偏好等其他因素的影响，这类被认为是完全随机缺失的，具有无偏性质。但是这类数据非常少，只有Yahoo！R3和Coat提供一个规模特别小的数据集。但是，有无偏数据的加成，去偏效果会有提升。由于这类数据少，所以使用这个数据集的相关论文论文也很少，只有四五篇（我找到的）。
那么由于无偏数据集规模的影响，而最近的去偏方法有很多一部分都是未使用无偏数据集的，相应的算法就不会考虑到无偏数据集，和使用无偏数据集的就非常大区别。如果只是改评价指标的话无法实现也没有意义。而如果是选用了带有无偏数据的数据集，那么未使用无偏数据集的那些方法应该是不能作为baseline的，只有那些传统的推荐算法可以作为baseline。
并且像通用的评价指标有Recall，NDCG，F1，这些可以与baseline作比较。如果要解决具体的问题，还得要使用特殊的指标来对具体问题进行验证说明。而且比如说像Yahoo！R3中的无偏数据集中每个用户仅与10个项目进行了交互，那么在选择评价指标时，Recall@K中的K值最大也只能是10。而MoviesLen或Facebook等数据集中，每个用户交互的项目能达到20或者是更多，那么在推荐topN的时候就会有很大的差距。
也就是说去偏方法不一样使用的数据集有很大可能是不一样的。
还有一种算法针对去除有关于时间序列的偏差，比如说用户的喜好和商品受欢迎程度都会因为时间发生变化，但是在Yahoo！R3和Coat数据集中没有时间维度上的属性。

