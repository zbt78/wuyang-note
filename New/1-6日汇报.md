## Debiasing Career Recommendations with Neural Fair Collaborative Filtering

偏差类型积累，方便找到新的偏差：
1. bias in the input embeddings due to the non-sensitive items, 
2. bias in the prediction outputs due to the sensitive items. 
3. 物品不会在很长时间内受欢迎；用户的喜欢也会随着时间变化

使用CF***嵌入***来去除*性别偏差*：CF embeddings for users from each protected group

权重: $w^{'}=w-\left( w\cdot v_B \right) v_B$ 

女性用户偏差方向: $v_{f\mathrm{e}mal\mathrm{e}}=\frac{1}{n_f}\left( f_1+f_2+...+f_n \right)$ , $f_1,f_2,...,f_n$ are vectors for each female user

整体性别偏差向量: $v_B=\frac{v_{f\mathrm{e}mal\mathrm{e}}-v_{mal\mathrm{e}}}{\left\| v_{f\mathrm{e}mal\mathrm{e}}-v_{mal\mathrm{e}} \right\|}$

对用户向量进行去偏: $p_{u}^{'}=p_u-\left( p_u\cdot v_B \right) v_B$, $p_u$ is user vector.

上面这些是性别去偏。

然后用一个*fairness penalty*来去掉*sensetive items*中的人口统计偏差，*eg. more men
than women choose computer science careers.*
## Self-Guided Learning to Denoise for Robust Recommendation
样本选择 和 样本重新加权   *sample selection methods* and *sample re-weighting methods*
样本选择严重依赖*样本分布*
样本重新加权也有如下限制：
- **Abandon of Hard Clean Interactions**: 一些干净的互动可能有很高的损失值，因此在重新加权的过程中被抛弃了 *aka.* hard yet clean interactions
- **Lack of Adaptivity and University**: 缺乏适应性和普遍性

SGDL分为两个时期：记忆期和自我主导学习期

在训练的早期阶段，被记忆的数据大多是容易和干净的交互，我们把它们作为去噪信号来收集，以指导接下来的去噪训练过程
## Interpolative Distillation for Unifying Biased and Debiased Recommendation

现有的策略：
- data imputation：评估缺失数据的影响，减少选择偏差
- regularization：引入正则化减少推荐列表的偏差
- causal inference：两个经典的因果框架potential outcome、structural causal models


分成两种环境（现实环境bias & 非现实环境debias,并且Db >> Dd），计算对于一个特定的 user-item pair，属于每一种环境的概率：P(E | U, I)。在以往的推荐模型中 只考虑了一种环境，也就是现实环境，并没有考虑非现实环境。

用P(R | U,I,E) & P(E | U,I) 来估算 P(R | U,I):
 $P(R|U,I) = \sum_{E}^{}P(E|U,I,R)\cdot P(E|U,I)$

### 4.2
#### 4.2.1
使用 biased and debiased model 训练得到最优参数，然后预测出 rb_hat,rd_hat 以此来得到$P(R|U,I,E=eb)$ 和 $P(R|U,I,E=ed)$ 

#### 4.2.2
如果 given (u,i) pair 更可能属于哪一种环境，那么相应的 *rb_hat* or *rd_hat* 就会更接近真实的 *r* 。 *rb_hat* and *rd_hat* 都是在各自环境中表现的最好的算法得到的。*rd_hat* 是 $P(R|U,I,E=eb)$ 的估计期望值，越接近期望就意味着 *r* 有更大的可能性 comes from $P(R|U,I,E=eb)$ ，那么因此 $P(E=ed |U,I)$  应该会更大。$$
w_b=\frac{L_b\left( \overline{r_b},r \right) \gamma}{L_b\left( \overline{r_b},r \right) \gamma +L_{\mathrm{d}}\left( \overline{r_{\mathrm{d}}},r \right) \gamma}\,\,w_{\mathrm{d}}=\frac{L_{\mathrm{d}}\left( \overline{r_{\mathrm{d}}},r \right) \gamma}{L_b\left( \overline{r_b},r \right) \gamma +L_{\mathrm{d}}\left( \overline{r_{\mathrm{d}}},r \right) \gamma}
$$$\gamma$ is a negative value, 保证$L_b\left( \overline{r_b},r \right)$ 越小时，$w_b$ 越大，说明当 $\overline{r_b}$ 越接近 $r$ 时，$w_b$ 越大。


#### 4.2.3
$r_*$ 是 $P(R|U,I)$ 的期望，$r_*=w_b\overline{r_b} +w_d\overline{r_d}$  
然后在两个训练集（包括biased和debiased）上训练新的模型，新模型的损失函数是让训练结果和 $r_*$ 做比较，并不是观察的评分 $r$ 。

#### 4.2.4 纳入未观察到的数据
使用 $\mathcal{D} _n=\mathcal{U} \times \mathcal{I} -\mathcal{D} _b\cup \mathcal{D} _{\mathrm{d}}$ 来表示未观察的数据。
$w_b^{'}$ and $w_d^{'}$ 表示 $P(E=eb|U,I)$ and $P(E=ed|U,I)$ 的插值
$r_*^{'}=w_b^{'}\overline{r_b} +w_d^{'}\overline{r_d}$
$$
w_{b}^{'}=\frac{L_b\left( \overline{r_b},\overline{r} \right) \gamma _2}{L_b\left( \overline{r_b},\overline{r} \right) \gamma _2+L_{\mathrm{d}}\left( \overline{r_{\mathrm{d}}},\overline{r} \right) \gamma _2}\,\,w_{\mathrm{d}}^{'}=\frac{L_{\mathrm{d}}\left( \overline{r_{\mathrm{d}}},\overline{r} \right) \gamma _2}{L_b\left( \overline{r_b},\overline{r} \right) \gamma _2+L_{\mathrm{d}}\left( \overline{r_{\mathrm{d}}},\overline{r} \right) \gamma _2}
$$

$L_b\left( \overline{r_b},\overline{r} \right)$ and $L_d\left( \overline{r_d},\overline{r} \right)$ is the distances between prediction of teachers and student.
模型为 $f_S\left( u,i;\theta \right)$ 使用模型的预测值和 $r_*^{'}$ 来作为损失函数的参数。
对模型进行训练，当损失函数最小时到超参数 $\theta$ .

和其他算法的不同点：
- 同时利用了有偏模型和无偏模型
- 从两种模型中学习一个新的模型，能处理事实和反事实环境
- 使用了未观察的数据来训练 *student* 模型

### 5.3
受欢迎程度是用 *item* 在训练数据中出现的频次决定的。

在不受欢迎的 *item* 中，InterD 更相信 *debiased-teacher* ，而在受欢迎的 *item* 中，InterD则更信赖 *biased-teacher* 。

在 *top-20* 中，*AutoDebias* 推荐的项目 *less-popular* 占的比较多， *MF* 推荐的项目 *popular* 占的比较多

## Yahoo！R3

拥有无偏评分数据的公开数据集：Yahoo！R3 和 Coat。

Yahoo！R3的训练集是**MNAR**(missing not at random)，测试集是**MCAR**(misssing completely at randon, no bias)。

**MAR**
missingness depend only on available information(例如依赖于年龄)
随机丢失意味着数据丢失的概率与丢失的数据本身无关，而仅与部分已观测到的数据(年龄)有关。也就是说，数据的缺失不是完全随机的，该类数据的缺失依赖于其他完全变量。
**MNAR**
missingness depend on unavailable information
有其他患者等待则抛硬币来决定记录与否，无其他患者等待则记录数据。但是否等待是无法观测、无法收集到的数据。

Yahoo! R3数据集还提供了一个使用**均匀策略**收集到的测试集：系统为5400位用户中的每个用户随机选取十首音乐作品，并要求该用户对这些音乐作品给予反馈。因此，Yahoo！R3的测试集可以被认为是完全随机缺失的（missing at complete random），即具有无偏性质。

本文仅选用Yahoo！R3数据集作为实验数据集是因为它是目前仅有的一个较大的，且提供在均匀策略下收集到的测试集的公开的推荐系统数据集。