## IPS

IPS中最关键的是损失函数,在训练过程中改变的是损失函数,以此来提高模型的精度,纠正偏差.亮点就是在损失函数上想办法,不像其他的方法是设计新的模型.

因为IPS要消除权值,针对的是整体所有用户对所有项目的交互的情况,而不是仅仅针对浏览过的项目.在此能够借助朴素贝叶斯或逻辑回归来先进行拟合,来得到所有的评级数据.

通过调整模型训练的交互示例的权重来调整数据分布的均匀性

缺点:可变性太大,模型方差大,难以估计倾向,在实际应用中效果不佳





## AutoDebias

AutoDebias是一种自动化去偏方法,能够有效减少推荐系统中的群体偏见和历史偏见,优点如下所示:

1. 自动化:AutoDebias能够自动检测和纠正推荐系统中的偏见,不需要手动设置或者调整偏见纠正参数,减少了人工干预,使系统的效率和可靠性更高
2. 多样性:能够检测各种常见的偏差,提高推荐系统的多样性
3. 可扩展:AutoDebias适用于各种推荐算法和数据集,并可以和其他的去偏方法就结合使用,更具适用性和可扩展性
4. 效果显著,AutoDebias再多个实验中表现出良好的去偏效果,能有效减少推荐系统的偏见





## InvPref

InvPref使用 random logging policy 来采集 uniform data，然后来监督model在有偏数据集上的训练。
需要找到由不能观察的干扰因子造成的潜在的偏差，然后得到普遍的去偏。
通过估计伪环境标签作为代理来捕获为观察到的干扰因子。
使用对抗学习的方式将不变偏好（即环境无关偏好）和变体偏好（即环境相关偏好）从可以观察的行为区分开来。
要在所有环境中找到$y_{hat}$最接近真实y的环境。

## Dual Unbias

把用户点击一个物品分成两部分来看,就是在这个用户观察到这个物品的同时还喜欢这个物品.

设计了一种新的损失函数,带有两个倾向权值,作用是通过消除未点击数据的偏差来提高推荐模型的准确性



## Double Robust

这个方法结合了两种前人的思想,第一个是EIB(Error Imputation Biased),这个方法计算每个确实评级的预测误差估计值,但是因为估计值的不准确性,不能很好地代表用户偏好,有很大的偏差.第二个是IPS反倾向得分(在之前也提到过),认为每个评级的预测误差与该评级的倾向成反比,这种倾向会导致泛化能力变差.DR提出一种双重健壮的联合学习方法,该方法同时考虑了观察到的数据和确实的数据,该方法结合了两个模型:一个是基于观察到的数据预测用户偏好的推荐模型,另一个是基于观察的和未观察到的数据估计数据丢失概率的缺失模型.

优点:大部分去偏方法依赖于单一的缺失数据模型,DR集成了两个缺失的数据模型,受到缺失数据模型的错误影响更小.解决EIB大偏差问题和IPS高方差问题.

## Enhanced Double Robust



## 问题:

- 训练数据是implicit还是explicit, 测试数据是implicit还是explicit?
- 测试数据如果是implicit的,那么标签全都是正样本, 在使用排序类的指标时如何进行计算呢?排序类的指标是需要负样本的吧, 在全都是正样本的情况下如何进行排序呢?比如auc,ndcg.
- 或者说是, explicit和implicit只是对训练时数据的限制,ie.训练时数据包含正负样本或只包含正样本,而测试数据在那种情况下都包含正样本和负样本.
- 负采样时,每个user的positem是选取这个用户的所有item,还是可以重复,可重复的意思就是 *每个用户的平均数据量 = (总训练数据数量/用户数量)*, 如果某个用户的数据量没达到平均数据量,同一个positem可能会出现多次
- **新思路:** 既然训练集中的项目得分是最高的, 那么在测试的时候, 率先把在训练集中出现的项目评分设为最低, 然后再进行排序, 得到topk项目, 与测试集中的进行对比, 计算评价指标
- 

## LSEM长短期记忆
