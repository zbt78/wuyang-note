今天主要对以后的工作做个规划。还没有想到创新点，个人感觉还是在以后的工作中想创新点吧。
参考其他论文计划使用的baseline：
- 贝叶斯个性化排序模型（BPR）
- 普通的矩阵分解模型（MF）
- 基于倾向分数的矩阵分解模型(MF-IPS)
- 相关性矩阵分解模型（RMF）
这些是比较经典的模型，不计划把sota作为baseline，没有信心做出比sota更好的效果。

## BPR学习
BPR算法的几个核心点：
- 每个用户之间的偏好行为相互独立
- 同一用户对不同物品的偏序相互独立
- <u,i,j>表示用户u对物品i的喜好大于物品j，写成 $i>_uj$
- 使用最大后验估计计算参数
$\overline{X}$表示用户集U和物品集I对应的$U\times I$的预测排序矩阵，分解后的用户矩阵为W和物品矩阵为H。
对于任意一个用户u，对应任意一个物品i有：
$$
\overline{x}_{ui}=\omega _u\bullet h_i=\sum_{f=1}^k{\omega _{uf}h_{if}}
$$
最终目标是找到合适的W和H，让$\overline{X}$和$X$最相似。

BPR的优化思路：
BPR是基于最大后验估计$P\left( W,H|>_u \right)$来求解模型参数W和H，这里用$\theta$来表示W、H，用$>_u$来代表用户u对应的所有物品的全序关系，转为优化$P\left( \theta|>_u \right)$。
$$
P\left( \theta |>_u \right) =\frac{P\left( >_u|\theta \right) P\left( \theta \right)}{P\left( >_u \right)}
$$
对任意用户u来说，$P\left(>_u\right)$对所有物品都一样，所以有：
$$
P\left( \theta |>_u \right) \propto P\left( >_u|\theta \right) P\left( \theta \right) 
$$
第一部分$P\left( >_u|\theta \right)$和数据集有关，第二部分$P\left( \theta \right)$和数据集无关。

然后每个用户之间的偏好行为相互独立，同一用户对不同物品偏序相互独立，所以有：
$$
\prod_{u\in U}{P\left( >_u|\theta \right)}=\prod_{\left( u,i,j \right) \in \left( U\times I\times I \right)}{P\left( i>_uj|\theta \right) ^{\delta \left( \left( u,i,j \right) \in D \right)}\left( 1-P\left( i>_uj|\theta \right) \right) ^{\delta \left( \left( u,i,j \right) \notin D \right)}}
$$
其中
$$
\delta \left( b \right) =\begin{cases}
	1&		if\,\,b\,\,is\,\,true\\
	0&		else\\
\end{cases}
$$
第一部分可以简化为：
$$
\prod_{u\in U}{P\left( >_u|\theta \right)}=\prod_{\left( u,i,j \right) \in D}{P\left( i>_uj|\theta \right)}
$$
对于$P\left( i>_uj|\theta \right)$这个概率，使用下面这个式子代替：
$$
P\left( i>_uj|\theta \right) =\sigma \left( \overline{x}_{uij}\left( \theta \right) \right) 
$$
$\sigma \left( x \right)$是sigmoid函数，在此使用为了方便优化计算。
对于$\bar{x}_{uij}\left( \theta \right)$这个式子，要满足当$i>_uj$时，$\bar{x}_{uij}\left( \theta \right)>0$，当$j>_ui$时，$\bar{x}_{uij}\left( \theta \right)<0$，
所以可以另$\bar{x}_{uij}=\bar{x}_{ui}-\bar{x}_{uj}$，
对于$\bar{x}_{ui}\left( \theta \right) ,\bar{x}_{uj}\left( \theta \right)$，就是矩阵$\bar{X}$对应位置的值。

最终，第一部分的优化目标转化为：
$$
\prod_{u\in U}{P\left( >_u|\theta \right)}=\prod_{\left( u,i,j \right) \in D}{\sigma \left( \bar{x}_{ui}-\bar{x}_{uj} \right)}
$$
对于第二部分，直接假设他服从均值为0，协方差矩阵为$\lambda _{\theta}I$的高斯分布：
$$
P\left( \theta \right) \sim N\left( 0,\lambda _{\theta}I \right) 
$$
然后最大后验估计函数得知，使用梯度下降法求解参数。


指标相关：
- 准确度指标：平均绝对误差（MAE）、均方误差根（RMSE）
- 集合推荐指标，用于Top-N推荐任务：精密度(Precision)、召回(Recall)、AUC和NDCG@K


后续工作：
把指标全都实现，留出统一接口，将来直接使用即可。
baseline也是，这些固定的东西要先完成，创新点的提出感觉是在这个过程中产生的。